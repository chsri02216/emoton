{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1H0FtVUkAVmIT1XlxbLrFXM1d02BEICRC",
      "authorship_tag": "ABX9TyPcYF/KYQuZxMqvPeh8nSE6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chsri02216/emoton/blob/main/Untitle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNZSBVjfzExs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkQZU60hRqWt",
        "outputId": "fcfcdfcf-4a38-4cd3-a495-59776d8af0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pxDru6q9zS7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiVgyZH0Rb8_",
        "outputId": "0e6c2d71-d153-45df-ae9e-ae49980a3602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6}\n",
            "{'PrivateTest', 'Training', 'PublicTest'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "35887it [05:07, 116.55it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "#/content/drive/MyDrive/probe/fer2013.csv\n",
        "data = pd.read_csv(\"drive/MyDrive/probes2/fer2013.csv\")\n",
        "\n",
        "#data = pd.read_csv(\"https://drive.google.com/file/d/1PpaJ8vAvw_6lK0Tu8_0xwMtyrmNIAodc/view?usp=sharing.csv\")\n",
        "data.head()\n",
        "\n",
        "\n",
        "labels = []\n",
        "usage = []\n",
        "\n",
        "for i in data[\"emotion\"]:\n",
        "    labels.append(i)\n",
        "    \n",
        "for i in data[\"Usage\"]:\n",
        "    usage.append(i)\n",
        "    \n",
        "print(set(labels))\n",
        "print(set(usage))\n",
        "\n",
        "\n",
        "\n",
        "count0 = 0\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "count3 = 0\n",
        "count4 = 0\n",
        "count5 = 0\n",
        "count6 = 0\n",
        "\n",
        "for i, j, k in tqdm(zip(data[\"emotion\"], data[\"pixels\"], data[\"Usage\"])):\n",
        "    pixel = []\n",
        "    #print(pixel)\n",
        "    pixels = j.split(' ')\n",
        "    for m in pixels:\n",
        "        value = float(m)\n",
        "        pixel.append(value)\n",
        "    pixel = np.array(pixel)\n",
        "    image = pixel.reshape(48, 48)\n",
        "    \n",
        "    if k == \"Training\":\n",
        "        if not os.path.exists(\"drive/MyDrive/probes2/train\"):\n",
        "            os.mkdir(\"drive/MyDrive/probes2/train\")\n",
        "        if i == 0:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Angry\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Angry\")\n",
        "                path = \"drive/MyDrive/probes2/train/Angry/\" + str(count0) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count0 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Angry/\" + str(count0) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count0 += 1    \n",
        "    # if k == \"Training\":\n",
        "    #     if not os.path.exists(\"drive/MyDrive/probes/train\"):\n",
        "    #       os.mkdir(\"drive/MyDrive/probes/train\")\n",
        "\n",
        "            \n",
        "    #     if i == 0:\n",
        "    #         if not os.path.exists(\"drive/MyDrive/probes/train/Angry\"):\n",
        "    #             os.mkdir(\"drive/MyDrive/probes/train/Angry\")\n",
        "    #             path = \"drive/MyDrive/probes/train/Angry/\" + str(count0) + \".jpg\"\n",
        "    #             cv2.imwrite(path , image)\n",
        "    #             count0 += 1\n",
        "    #         else:\n",
        "    #             path = \"drive/MyDrive/probes/train/Angry/\" + str(count0) + \".jpg\"\n",
        "    #             cv2.imwrite(path , image)\n",
        "    #             count0 += 1\n",
        "        # if i == 1:\n",
        "        #     if not os.path.exists(\"drive/MyDrive/probe/train/Disgust\"):\n",
        "        #         os.mkdir(\"drive/MyDrive/probe/train/Disgust\")\n",
        "        #         path = \"drive/MyDrive/probe/train/Disgust/\" + str(count1) + \".jpg\"\n",
        "        #         cv2.imwrite(path , image)\n",
        "        #         count1 += 1\n",
        "        #     else:\n",
        "        #         path = \"drive/MyDrive/probe/train/Disgust/\" + str(count1) + \".jpg\"\n",
        "        #         cv2.imwrite(path , image)\n",
        "        #         count1 += 1\n",
        "        if i == 2:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Fear\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Fear\")\n",
        "                path = \"drive/MyDrive/probes2/train/Fear/\" + str(count2) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count2 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Fear/\" + str(count2) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count2 += 1\n",
        "        if i == 3:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Happy\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Happy\")\n",
        "                path = \"drive/MyDrive/probes2/train/Happy/\" + str(count3) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count3 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Happy/\" + str(count3) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count3 += 1\n",
        "        if i == 4:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Sad\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Sad\")\n",
        "                path = \"drive/MyDrive/probes2/train/Sad/\" + str(count4) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count4 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Sad/\" + str(count4) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count4 += 1\n",
        "        if i == 5:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Surprise\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Surprise\")\n",
        "                path = \"drive/MyDrive/probes2/train/Surprise/\" + str(count5) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count5 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Surprise/\" + str(count5) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count5 += 1\n",
        "        if i == 6:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/train/Neutral\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/train/Neutral\")\n",
        "                path = \"drive/MyDrive/probes2/train/Neutral/\" + str(count6) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count6 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/train/Neutral/\" + str(count6) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count6 += 1\n",
        "    else:\n",
        "        if not os.path.exists(\"drive/MyDrive/probes2/validation\"):\n",
        "            os.mkdir(\"drive/MyDrive/probes2/validation\")\n",
        "        if i == 0:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Angry\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Angry\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Angry/\" + str(count0) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count0 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Angry/\" + str(count0) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count0 += 1\n",
        "        # if i == 1:\n",
        "        #     if not os.path.exists(\"drive/MyDrive/probe/validation/Disgust\"):\n",
        "        #         os.mkdir(\"drive/MyDrive/probe/validation/Disgust\")\n",
        "        #         path = \"drive/MyDrive/probe/validation/Disgust/\" + str(count1) + \".jpg\"\n",
        "        #         cv2.imwrite(path , image)\n",
        "        #         count1 += 1\n",
        "        #     else:\n",
        "        #         path = \"drive/MyDrive/probe/validation/Disgust/\" + str(count1) + \".jpg\"\n",
        "        #         cv2.imwrite(path , image)\n",
        "        #         count1 += 1\n",
        "        if i == 2:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Fear\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Fear\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Fear/\" + str(count2) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count2 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Fear/\" + str(count2) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count2 += 1\n",
        "        if i == 3:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Happy\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Happy\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Happy/\" + str(count3) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count3 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Happy/\" + str(count3) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count3 += 1\n",
        "        if i == 4:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Sad\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Sad\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Sad/\" + str(count4) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count4 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Sad/\" + str(count4) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count4 += 1\n",
        "        if i == 5:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Surprise\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Surprise\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Surprise/\" + str(count5) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count5 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Surprise/\" + str(count5) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count5 += 1\n",
        "        if i == 6:\n",
        "            if not os.path.exists(\"drive/MyDrive/probes2/validation/Neutral\"):\n",
        "                os.mkdir(\"drive/MyDrive/probes2/validation/Neutral\")\n",
        "                path = \"drive/MyDrive/probes2/validation/Neutral/\" + str(count6) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count6 += 1\n",
        "            else:\n",
        "                path = \"drive/MyDrive/probes2/validation/Neutral/\" + str(count6) + \".jpg\"\n",
        "                cv2.imwrite(path , image)\n",
        "                count6 += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ftf81j3dzZ7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "train_directory = \"drive/MyDrive/probes2/train/\"\n",
        "train_dir = os.listdir(train_directory)\n",
        "classes = []\n",
        "\n",
        "for folder in train_dir:\n",
        "    classes.append(folder)\n",
        "\n",
        "train_counts = []\n",
        "\n",
        "for folder in train_dir:\n",
        "    class_path = train_directory + folder + \"/\"\n",
        "    list_train = []\n",
        "    count = 0\n",
        "    for file in os.listdir(class_path):\n",
        "        count +=1\n",
        "    \n",
        "    train_counts.append(count)\n",
        "    \n",
        "train_counts\n",
        "\n",
        "\n",
        "plt.bar(classes, train_counts, width=0.5)\n",
        "plt.title(\"Bar Graph of Train Data\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Counts\")\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter(classes, train_counts)\n",
        "plt.plot(classes, train_counts, '-o')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "wr4_sL1gRiTR",
        "outputId": "be7742a7-ff9f-4265-bb27-fecc48822216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2DecLOorzeL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Dense, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pydot_ng\n",
        "import graphviz\n",
        "import os\n",
        "\n",
        "num_classes = 6\n",
        "\n",
        "Img_Height = 48\n",
        "Img_width = 48\n",
        "\n",
        "batch_size = 32\n",
        "train_directory = \"drive/MyDrive/probes2/train\"\n",
        "train_dir = os.listdir(train_directory)\n",
        "validation_directory = \"drive/MyDrive/probes2/validation\"\n",
        "validation_dir = os.listdir(validation_directory)\n",
        "\n",
        "#train_dir = \"train\"\n",
        "#validation_dir = \"validation\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=60,\n",
        "                                   shear_range=0.5,\n",
        "                                   zoom_range=0.5,\n",
        "                                   width_shift_range=0.5,\n",
        "                                   height_shift_range=0.5,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_directory,\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    target_size=(Img_Height, Img_width),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_directory,\n",
        "                                                              color_mode='grayscale',\n",
        "                                                              target_size=(Img_Height, Img_width),\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              class_mode='categorical',\n",
        "                                                              shuffle=True)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Block-1: The First Convolutional Block\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
        "                 kernel_initializer='he_normal',\n",
        "                 activation=\"elu\", \n",
        "                 input_shape=(Img_Height, Img_width, 1), \n",
        "                 name=\"Conv1\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm1\"))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
        "                 kernel_initializer='he_normal', \n",
        "                 activation=\"elu\", name=\"Conv2\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm2\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool1\"))\n",
        "model.add(Dropout(0.2, name=\"Dropout1\"))\n",
        "\n",
        "# Block-2: The Second Convolutional Block\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', \n",
        "                 kernel_initializer='he_normal',\n",
        "                 activation=\"elu\", name=\"Conv3\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm3\"))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',\n",
        "                 kernel_initializer='he_normal', \n",
        "                 activation=\"elu\", name=\"Conv4\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm4\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool2\"))\n",
        "model.add(Dropout(0.2, name=\"Dropout2\"))\n",
        "\n",
        "# Block-3: The Third Convolutional Block\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
        "                 kernel_initializer='he_normal', \n",
        "                 activation=\"elu\", name=\"Conv5\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm5\"))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
        "                 kernel_initializer='he_normal',\n",
        "                 activation=\"elu\", name=\"Conv6\"))\n",
        "\n",
        "model.add(BatchNormalization(name=\"Batch_Norm6\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool3\"))\n",
        "model.add(Dropout(0.2, name=\"Dropout3\"))\n",
        "\n",
        "# Block-4: The Fully Connected Block\n",
        "\n",
        "model.add(Flatten(name=\"Flatten\"))\n",
        "model.add(Dense(64, activation=\"elu\", kernel_initializer='he_normal', name=\"Dense\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Norm7\"))\n",
        "model.add(Dropout(0.5, name=\"Dropout4\"))\n",
        "\n",
        "# Block-5: The Output Block\n",
        "\n",
        "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal', name = \"Output\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"emotions.h5\", monitor='accuracy', verbose=1,\n",
        "                              save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=10, \n",
        "                           min_lr=0.0001, verbose = 1)\n",
        "\n",
        "logdir='logs'\n",
        "tensorboard_Visualization = TensorBoard(log_dir=logdir, histogram_freq=False)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr = 0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "train_samples = 28353\n",
        "validation_samples = 3534\n",
        "epochs = 150\n",
        "batch_size = 64\n",
        "\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch = train_samples//batch_size,\n",
        "          epochs = epochs,\n",
        "          callbacks = [checkpoint, reduce, tensorboard_Visualization],\n",
        "          validation_data = validation_generator,\n",
        "          validation_steps = validation_samples//batch_size,\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#model.save('drive/MyDrive/probe/saved_model/my_model') \n",
        "#model.save('drive/MyDrive/emotion.h5')\n",
        "#Sequential.save('drive/MyDrive/emotion.h5')\n",
        "\n",
        "\n",
        "model.save('drive/MyDrive/probes2/saved_model/my_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiI56Vn9RlPI",
        "outputId": "a185934d-a087-4d73-c8df-6c2447ea60bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28273 images belonging to 6 classes.\n",
            "Found 7067 images belonging to 6 classes.\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 2.1145 - accuracy: 0.2015\n",
            "Epoch 00001: accuracy improved from -inf to 0.20154, saving model to emotions.h5\n",
            "443/443 [==============================] - 318s 713ms/step - loss: 2.1145 - accuracy: 0.2015 - val_loss: 1.7383 - val_accuracy: 0.2580 - lr: 0.0010\n",
            "Epoch 2/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.8385 - accuracy: 0.2281\n",
            "Epoch 00002: accuracy improved from 0.20154 to 0.22806, saving model to emotions.h5\n",
            "443/443 [==============================] - 326s 736ms/step - loss: 1.8385 - accuracy: 0.2281 - val_loss: 1.7241 - val_accuracy: 0.2648 - lr: 0.0010\n",
            "Epoch 3/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7709 - accuracy: 0.2413\n",
            "Epoch 00003: accuracy improved from 0.22806 to 0.24130, saving model to emotions.h5\n",
            "443/443 [==============================] - 314s 710ms/step - loss: 1.7709 - accuracy: 0.2413 - val_loss: 1.7278 - val_accuracy: 0.2665 - lr: 0.0010\n",
            "Epoch 4/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7528 - accuracy: 0.2524\n",
            "Epoch 00004: accuracy improved from 0.24130 to 0.25238, saving model to emotions.h5\n",
            "443/443 [==============================] - 324s 730ms/step - loss: 1.7528 - accuracy: 0.2524 - val_loss: 1.7179 - val_accuracy: 0.2750 - lr: 0.0010\n",
            "Epoch 5/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7426 - accuracy: 0.2539\n",
            "Epoch 00005: accuracy improved from 0.25238 to 0.25387, saving model to emotions.h5\n",
            "443/443 [==============================] - 314s 709ms/step - loss: 1.7426 - accuracy: 0.2539 - val_loss: 1.7447 - val_accuracy: 0.2483 - lr: 0.0010\n",
            "Epoch 6/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7440 - accuracy: 0.2508\n",
            "Epoch 00006: accuracy did not improve from 0.25387\n",
            "443/443 [==============================] - 323s 729ms/step - loss: 1.7440 - accuracy: 0.2508 - val_loss: 1.7460 - val_accuracy: 0.2438 - lr: 0.0010\n",
            "Epoch 7/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7387 - accuracy: 0.2587\n",
            "Epoch 00007: accuracy improved from 0.25387 to 0.25867, saving model to emotions.h5\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.7387 - accuracy: 0.2587 - val_loss: 1.7097 - val_accuracy: 0.2824 - lr: 0.0010\n",
            "Epoch 8/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7476 - accuracy: 0.2539\n",
            "Epoch 00008: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 312s 703ms/step - loss: 1.7476 - accuracy: 0.2539 - val_loss: 1.7316 - val_accuracy: 0.2625 - lr: 0.0010\n",
            "Epoch 9/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7438 - accuracy: 0.2535\n",
            "Epoch 00009: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 322s 727ms/step - loss: 1.7438 - accuracy: 0.2535 - val_loss: 1.7326 - val_accuracy: 0.2415 - lr: 0.0010\n",
            "Epoch 10/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7403 - accuracy: 0.2525\n",
            "Epoch 00010: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 321s 724ms/step - loss: 1.7403 - accuracy: 0.2525 - val_loss: 1.7269 - val_accuracy: 0.2705 - lr: 0.0010\n",
            "Epoch 11/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7386 - accuracy: 0.2523\n",
            "Epoch 00011: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 311s 703ms/step - loss: 1.7386 - accuracy: 0.2523 - val_loss: 1.7243 - val_accuracy: 0.2562 - lr: 0.0010\n",
            "Epoch 12/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7363 - accuracy: 0.2540\n",
            "Epoch 00012: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 312s 704ms/step - loss: 1.7363 - accuracy: 0.2540 - val_loss: 1.7350 - val_accuracy: 0.2625 - lr: 0.0010\n",
            "Epoch 13/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7370 - accuracy: 0.2568\n",
            "Epoch 00013: accuracy did not improve from 0.25867\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.7370 - accuracy: 0.2568 - val_loss: 1.7641 - val_accuracy: 0.2369 - lr: 0.0010\n",
            "Epoch 14/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7341 - accuracy: 0.2611\n",
            "Epoch 00014: accuracy improved from 0.25867 to 0.26108, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.7341 - accuracy: 0.2611 - val_loss: 1.7165 - val_accuracy: 0.2705 - lr: 0.0010\n",
            "Epoch 15/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7401 - accuracy: 0.2496\n",
            "Epoch 00015: accuracy did not improve from 0.26108\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.7401 - accuracy: 0.2496 - val_loss: 1.7147 - val_accuracy: 0.2625 - lr: 0.0010\n",
            "Epoch 16/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7327 - accuracy: 0.2610\n",
            "Epoch 00016: accuracy did not improve from 0.26108\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.7327 - accuracy: 0.2610 - val_loss: 1.7232 - val_accuracy: 0.2670 - lr: 0.0010\n",
            "Epoch 17/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7295 - accuracy: 0.2647\n",
            "Epoch 00017: accuracy improved from 0.26108 to 0.26474, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.7295 - accuracy: 0.2647 - val_loss: 1.7013 - val_accuracy: 0.2636 - lr: 0.0010\n",
            "Epoch 18/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7335 - accuracy: 0.2567\n",
            "Epoch 00018: accuracy did not improve from 0.26474\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.7335 - accuracy: 0.2567 - val_loss: 1.7188 - val_accuracy: 0.2580 - lr: 0.0010\n",
            "Epoch 19/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7284 - accuracy: 0.2625\n",
            "Epoch 00019: accuracy did not improve from 0.26474\n",
            "443/443 [==============================] - 311s 701ms/step - loss: 1.7284 - accuracy: 0.2625 - val_loss: 1.7028 - val_accuracy: 0.2710 - lr: 0.0010\n",
            "Epoch 20/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7243 - accuracy: 0.2659\n",
            "Epoch 00020: accuracy improved from 0.26474 to 0.26594, saving model to emotions.h5\n",
            "443/443 [==============================] - 307s 694ms/step - loss: 1.7243 - accuracy: 0.2659 - val_loss: 1.7011 - val_accuracy: 0.2733 - lr: 0.0010\n",
            "Epoch 21/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.7222 - accuracy: 0.2585\n",
            "Epoch 00021: accuracy did not improve from 0.26594\n",
            "443/443 [==============================] - 315s 711ms/step - loss: 1.7222 - accuracy: 0.2585 - val_loss: 1.7014 - val_accuracy: 0.2773 - lr: 0.0010\n",
            "Epoch 22/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6993 - accuracy: 0.2803\n",
            "Epoch 00022: accuracy improved from 0.26594 to 0.28026, saving model to emotions.h5\n",
            "443/443 [==============================] - 312s 703ms/step - loss: 1.6993 - accuracy: 0.2803 - val_loss: 1.6480 - val_accuracy: 0.3108 - lr: 0.0010\n",
            "Epoch 23/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6902 - accuracy: 0.2882\n",
            "Epoch 00023: accuracy improved from 0.28026 to 0.28816, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.6902 - accuracy: 0.2882 - val_loss: 1.6236 - val_accuracy: 0.3438 - lr: 0.0010\n",
            "Epoch 24/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6677 - accuracy: 0.3024\n",
            "Epoch 00024: accuracy improved from 0.28816 to 0.30238, saving model to emotions.h5\n",
            "443/443 [==============================] - 302s 681ms/step - loss: 1.6677 - accuracy: 0.3024 - val_loss: 1.8025 - val_accuracy: 0.2977 - lr: 0.0010\n",
            "Epoch 25/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6415 - accuracy: 0.3143\n",
            "Epoch 00025: accuracy improved from 0.30238 to 0.31431, saving model to emotions.h5\n",
            "443/443 [==============================] - 303s 684ms/step - loss: 1.6415 - accuracy: 0.3143 - val_loss: 1.5308 - val_accuracy: 0.3852 - lr: 0.0010\n",
            "Epoch 26/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6230 - accuracy: 0.3232\n",
            "Epoch 00026: accuracy improved from 0.31431 to 0.32321, saving model to emotions.h5\n",
            "443/443 [==============================] - 300s 677ms/step - loss: 1.6230 - accuracy: 0.3232 - val_loss: 1.7553 - val_accuracy: 0.3415 - lr: 0.0010\n",
            "Epoch 27/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6132 - accuracy: 0.3275\n",
            "Epoch 00027: accuracy improved from 0.32321 to 0.32753, saving model to emotions.h5\n",
            "443/443 [==============================] - 302s 681ms/step - loss: 1.6132 - accuracy: 0.3275 - val_loss: 1.4495 - val_accuracy: 0.4131 - lr: 0.0010\n",
            "Epoch 28/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.6065 - accuracy: 0.3409\n",
            "Epoch 00028: accuracy improved from 0.32753 to 0.34086, saving model to emotions.h5\n",
            "443/443 [==============================] - 306s 691ms/step - loss: 1.6065 - accuracy: 0.3409 - val_loss: 1.4886 - val_accuracy: 0.4153 - lr: 0.0010\n",
            "Epoch 29/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5822 - accuracy: 0.3502\n",
            "Epoch 00029: accuracy improved from 0.34086 to 0.35017, saving model to emotions.h5\n",
            "443/443 [==============================] - 305s 689ms/step - loss: 1.5822 - accuracy: 0.3502 - val_loss: 1.4697 - val_accuracy: 0.4426 - lr: 0.0010\n",
            "Epoch 30/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5674 - accuracy: 0.3593\n",
            "Epoch 00030: accuracy improved from 0.35017 to 0.35927, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 696ms/step - loss: 1.5674 - accuracy: 0.3593 - val_loss: 1.4949 - val_accuracy: 0.4159 - lr: 0.0010\n",
            "Epoch 31/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5665 - accuracy: 0.3591\n",
            "Epoch 00031: accuracy did not improve from 0.35927\n",
            "443/443 [==============================] - 307s 693ms/step - loss: 1.5665 - accuracy: 0.3591 - val_loss: 1.3742 - val_accuracy: 0.4818 - lr: 0.0010\n",
            "Epoch 32/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5530 - accuracy: 0.3685\n",
            "Epoch 00032: accuracy improved from 0.35927 to 0.36851, saving model to emotions.h5\n",
            "443/443 [==============================] - 307s 692ms/step - loss: 1.5530 - accuracy: 0.3685 - val_loss: 1.3390 - val_accuracy: 0.4773 - lr: 0.0010\n",
            "Epoch 33/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5474 - accuracy: 0.3702\n",
            "Epoch 00033: accuracy improved from 0.36851 to 0.37017, saving model to emotions.h5\n",
            "443/443 [==============================] - 307s 692ms/step - loss: 1.5474 - accuracy: 0.3702 - val_loss: 1.2786 - val_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 34/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5292 - accuracy: 0.3790\n",
            "Epoch 00034: accuracy improved from 0.37017 to 0.37900, saving model to emotions.h5\n",
            "443/443 [==============================] - 306s 690ms/step - loss: 1.5292 - accuracy: 0.3790 - val_loss: 1.4611 - val_accuracy: 0.4398 - lr: 0.0010\n",
            "Epoch 35/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.3806\n",
            "Epoch 00035: accuracy improved from 0.37900 to 0.38057, saving model to emotions.h5\n",
            "443/443 [==============================] - 305s 689ms/step - loss: 1.5316 - accuracy: 0.3806 - val_loss: 1.3202 - val_accuracy: 0.4761 - lr: 0.0010\n",
            "Epoch 36/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3787\n",
            "Epoch 00036: accuracy did not improve from 0.38057\n",
            "443/443 [==============================] - 306s 690ms/step - loss: 1.5284 - accuracy: 0.3787 - val_loss: 1.2824 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 37/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5069 - accuracy: 0.3948\n",
            "Epoch 00037: accuracy improved from 0.38057 to 0.39482, saving model to emotions.h5\n",
            "443/443 [==============================] - 307s 694ms/step - loss: 1.5069 - accuracy: 0.3948 - val_loss: 1.3492 - val_accuracy: 0.4699 - lr: 0.0010\n",
            "Epoch 38/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5001 - accuracy: 0.3915\n",
            "Epoch 00038: accuracy did not improve from 0.39482\n",
            "443/443 [==============================] - 308s 695ms/step - loss: 1.5001 - accuracy: 0.3915 - val_loss: 1.2374 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 39/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5032 - accuracy: 0.3899\n",
            "Epoch 00039: accuracy did not improve from 0.39482\n",
            "443/443 [==============================] - 308s 695ms/step - loss: 1.5032 - accuracy: 0.3899 - val_loss: 1.2210 - val_accuracy: 0.5159 - lr: 0.0010\n",
            "Epoch 40/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.5006 - accuracy: 0.3921\n",
            "Epoch 00040: accuracy did not improve from 0.39482\n",
            "443/443 [==============================] - 307s 693ms/step - loss: 1.5006 - accuracy: 0.3921 - val_loss: 1.3745 - val_accuracy: 0.4563 - lr: 0.0010\n",
            "Epoch 41/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4991 - accuracy: 0.3929\n",
            "Epoch 00041: accuracy did not improve from 0.39482\n",
            "443/443 [==============================] - 307s 694ms/step - loss: 1.4991 - accuracy: 0.3929 - val_loss: 1.2162 - val_accuracy: 0.5312 - lr: 0.0010\n",
            "Epoch 42/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4935 - accuracy: 0.4026\n",
            "Epoch 00042: accuracy improved from 0.39482 to 0.40258, saving model to emotions.h5\n",
            "443/443 [==============================] - 324s 732ms/step - loss: 1.4935 - accuracy: 0.4026 - val_loss: 1.2588 - val_accuracy: 0.4847 - lr: 0.0010\n",
            "Epoch 43/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4932 - accuracy: 0.3939\n",
            "Epoch 00043: accuracy did not improve from 0.40258\n",
            "443/443 [==============================] - 315s 710ms/step - loss: 1.4932 - accuracy: 0.3939 - val_loss: 1.2183 - val_accuracy: 0.5375 - lr: 0.0010\n",
            "Epoch 44/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.4072\n",
            "Epoch 00044: accuracy improved from 0.40258 to 0.40717, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.4713 - accuracy: 0.4072 - val_loss: 1.2504 - val_accuracy: 0.5108 - lr: 0.0010\n",
            "Epoch 45/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4036\n",
            "Epoch 00045: accuracy did not improve from 0.40717\n",
            "443/443 [==============================] - 307s 694ms/step - loss: 1.4767 - accuracy: 0.4036 - val_loss: 1.2564 - val_accuracy: 0.4943 - lr: 0.0010\n",
            "Epoch 46/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.4130\n",
            "Epoch 00046: accuracy improved from 0.40717 to 0.41295, saving model to emotions.h5\n",
            "443/443 [==============================] - 308s 694ms/step - loss: 1.4642 - accuracy: 0.4130 - val_loss: 1.2813 - val_accuracy: 0.4881 - lr: 0.0010\n",
            "Epoch 47/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.4108\n",
            "Epoch 00047: accuracy did not improve from 0.41295\n",
            "443/443 [==============================] - 306s 691ms/step - loss: 1.4718 - accuracy: 0.4108 - val_loss: 1.2516 - val_accuracy: 0.5114 - lr: 0.0010\n",
            "Epoch 48/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4546 - accuracy: 0.4195\n",
            "Epoch 00048: accuracy improved from 0.41295 to 0.41951, saving model to emotions.h5\n",
            "443/443 [==============================] - 307s 692ms/step - loss: 1.4546 - accuracy: 0.4195 - val_loss: 1.2206 - val_accuracy: 0.5125 - lr: 0.0010\n",
            "Epoch 49/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4680 - accuracy: 0.4069\n",
            "Epoch 00049: accuracy did not improve from 0.41951\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.4680 - accuracy: 0.4069 - val_loss: 1.2044 - val_accuracy: 0.5068 - lr: 0.0010\n",
            "Epoch 50/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4501 - accuracy: 0.4197\n",
            "Epoch 00050: accuracy improved from 0.41951 to 0.41967, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.4501 - accuracy: 0.4197 - val_loss: 1.1755 - val_accuracy: 0.5352 - lr: 0.0010\n",
            "Epoch 51/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4529 - accuracy: 0.4188\n",
            "Epoch 00051: accuracy did not improve from 0.41967\n",
            "443/443 [==============================] - 311s 703ms/step - loss: 1.4529 - accuracy: 0.4188 - val_loss: 1.1951 - val_accuracy: 0.5364 - lr: 0.0010\n",
            "Epoch 52/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4465 - accuracy: 0.4204\n",
            "Epoch 00052: accuracy improved from 0.41967 to 0.42036, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.4465 - accuracy: 0.4204 - val_loss: 1.1847 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 53/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4384 - accuracy: 0.4210\n",
            "Epoch 00053: accuracy improved from 0.42036 to 0.42102, saving model to emotions.h5\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.4384 - accuracy: 0.4210 - val_loss: 1.1796 - val_accuracy: 0.5398 - lr: 0.0010\n",
            "Epoch 54/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4369 - accuracy: 0.4254\n",
            "Epoch 00054: accuracy improved from 0.42102 to 0.42537, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.4369 - accuracy: 0.4254 - val_loss: 1.1831 - val_accuracy: 0.5273 - lr: 0.0010\n",
            "Epoch 55/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4417 - accuracy: 0.4262\n",
            "Epoch 00055: accuracy improved from 0.42537 to 0.42624, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.4417 - accuracy: 0.4262 - val_loss: 1.1423 - val_accuracy: 0.5528 - lr: 0.0010\n",
            "Epoch 56/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4403 - accuracy: 0.4223\n",
            "Epoch 00056: accuracy did not improve from 0.42624\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.4403 - accuracy: 0.4223 - val_loss: 1.2799 - val_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 57/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4347 - accuracy: 0.4281\n",
            "Epoch 00057: accuracy improved from 0.42624 to 0.42815, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.4347 - accuracy: 0.4281 - val_loss: 1.1916 - val_accuracy: 0.5392 - lr: 0.0010\n",
            "Epoch 58/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4276 - accuracy: 0.4311\n",
            "Epoch 00058: accuracy improved from 0.42815 to 0.43108, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 699ms/step - loss: 1.4276 - accuracy: 0.4311 - val_loss: 1.2962 - val_accuracy: 0.4835 - lr: 0.0010\n",
            "Epoch 59/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4291 - accuracy: 0.4296\n",
            "Epoch 00059: accuracy did not improve from 0.43108\n",
            "443/443 [==============================] - 308s 696ms/step - loss: 1.4291 - accuracy: 0.4296 - val_loss: 1.2059 - val_accuracy: 0.5352 - lr: 0.0010\n",
            "Epoch 60/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4305 - accuracy: 0.4276\n",
            "Epoch 00060: accuracy did not improve from 0.43108\n",
            "443/443 [==============================] - 308s 695ms/step - loss: 1.4305 - accuracy: 0.4276 - val_loss: 1.1923 - val_accuracy: 0.5443 - lr: 0.0010\n",
            "Epoch 61/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4255 - accuracy: 0.4282\n",
            "Epoch 00061: accuracy did not improve from 0.43108\n",
            "443/443 [==============================] - 308s 695ms/step - loss: 1.4255 - accuracy: 0.4282 - val_loss: 1.1873 - val_accuracy: 0.5386 - lr: 0.0010\n",
            "Epoch 62/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4207 - accuracy: 0.4306\n",
            "Epoch 00062: accuracy did not improve from 0.43108\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.4207 - accuracy: 0.4306 - val_loss: 1.1474 - val_accuracy: 0.5489 - lr: 0.0010\n",
            "Epoch 63/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4203 - accuracy: 0.4392\n",
            "Epoch 00063: accuracy improved from 0.43108 to 0.43919, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 697ms/step - loss: 1.4203 - accuracy: 0.4392 - val_loss: 1.1621 - val_accuracy: 0.5426 - lr: 0.0010\n",
            "Epoch 64/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4095 - accuracy: 0.4379\n",
            "Epoch 00064: accuracy did not improve from 0.43919\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.4095 - accuracy: 0.4379 - val_loss: 1.1353 - val_accuracy: 0.5557 - lr: 0.0010\n",
            "Epoch 65/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4062 - accuracy: 0.4424\n",
            "Epoch 00065: accuracy improved from 0.43919 to 0.44241, saving model to emotions.h5\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.4062 - accuracy: 0.4424 - val_loss: 1.1723 - val_accuracy: 0.5528 - lr: 0.0010\n",
            "Epoch 66/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4094 - accuracy: 0.4413\n",
            "Epoch 00066: accuracy did not improve from 0.44241\n",
            "443/443 [==============================] - 311s 701ms/step - loss: 1.4094 - accuracy: 0.4413 - val_loss: 1.2186 - val_accuracy: 0.5318 - lr: 0.0010\n",
            "Epoch 67/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4124 - accuracy: 0.4390\n",
            "Epoch 00067: accuracy did not improve from 0.44241\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.4124 - accuracy: 0.4390 - val_loss: 1.1393 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 68/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3999 - accuracy: 0.4429\n",
            "Epoch 00068: accuracy improved from 0.44241 to 0.44286, saving model to emotions.h5\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.3999 - accuracy: 0.4429 - val_loss: 1.1250 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 69/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4001 - accuracy: 0.4494\n",
            "Epoch 00069: accuracy improved from 0.44286 to 0.44942, saving model to emotions.h5\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.4001 - accuracy: 0.4494 - val_loss: 1.1994 - val_accuracy: 0.5233 - lr: 0.0010\n",
            "Epoch 70/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4087 - accuracy: 0.4385\n",
            "Epoch 00070: accuracy did not improve from 0.44942\n",
            "443/443 [==============================] - 319s 720ms/step - loss: 1.4087 - accuracy: 0.4385 - val_loss: 1.1479 - val_accuracy: 0.5585 - lr: 0.0010\n",
            "Epoch 71/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3876 - accuracy: 0.4549\n",
            "Epoch 00071: accuracy improved from 0.44942 to 0.45485, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.3876 - accuracy: 0.4549 - val_loss: 1.1483 - val_accuracy: 0.5409 - lr: 0.0010\n",
            "Epoch 72/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.4027 - accuracy: 0.4448\n",
            "Epoch 00072: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.4027 - accuracy: 0.4448 - val_loss: 1.1158 - val_accuracy: 0.5659 - lr: 0.0010\n",
            "Epoch 73/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3947 - accuracy: 0.4450\n",
            "Epoch 00073: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.3947 - accuracy: 0.4450 - val_loss: 1.1850 - val_accuracy: 0.5398 - lr: 0.0010\n",
            "Epoch 74/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3982 - accuracy: 0.4472\n",
            "Epoch 00074: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 311s 701ms/step - loss: 1.3982 - accuracy: 0.4472 - val_loss: 1.1097 - val_accuracy: 0.5682 - lr: 0.0010\n",
            "Epoch 75/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3922 - accuracy: 0.4506\n",
            "Epoch 00075: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 309s 698ms/step - loss: 1.3922 - accuracy: 0.4506 - val_loss: 1.1455 - val_accuracy: 0.5472 - lr: 0.0010\n",
            "Epoch 76/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3940 - accuracy: 0.4487\n",
            "Epoch 00076: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.3940 - accuracy: 0.4487 - val_loss: 1.0936 - val_accuracy: 0.5807 - lr: 0.0010\n",
            "Epoch 77/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3931 - accuracy: 0.4478\n",
            "Epoch 00077: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 310s 699ms/step - loss: 1.3931 - accuracy: 0.4478 - val_loss: 1.1009 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 78/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3911 - accuracy: 0.4457\n",
            "Epoch 00078: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 320s 721ms/step - loss: 1.3911 - accuracy: 0.4457 - val_loss: 1.1197 - val_accuracy: 0.5665 - lr: 0.0010\n",
            "Epoch 79/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3950 - accuracy: 0.4483\n",
            "Epoch 00079: accuracy did not improve from 0.45485\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.3950 - accuracy: 0.4483 - val_loss: 1.0782 - val_accuracy: 0.5807 - lr: 0.0010\n",
            "Epoch 80/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3764 - accuracy: 0.4584\n",
            "Epoch 00080: accuracy improved from 0.45485 to 0.45837, saving model to emotions.h5\n",
            "443/443 [==============================] - 311s 701ms/step - loss: 1.3764 - accuracy: 0.4584 - val_loss: 1.0661 - val_accuracy: 0.5790 - lr: 0.0010\n",
            "Epoch 81/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3777 - accuracy: 0.4541\n",
            "Epoch 00081: accuracy did not improve from 0.45837\n",
            "443/443 [==============================] - 320s 722ms/step - loss: 1.3777 - accuracy: 0.4541 - val_loss: 1.0817 - val_accuracy: 0.5801 - lr: 0.0010\n",
            "Epoch 82/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3846 - accuracy: 0.4507\n",
            "Epoch 00082: accuracy did not improve from 0.45837\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.3846 - accuracy: 0.4507 - val_loss: 1.1506 - val_accuracy: 0.5557 - lr: 0.0010\n",
            "Epoch 83/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.4601\n",
            "Epoch 00083: accuracy improved from 0.45837 to 0.46007, saving model to emotions.h5\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.3761 - accuracy: 0.4601 - val_loss: 1.1266 - val_accuracy: 0.5682 - lr: 0.0010\n",
            "Epoch 84/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3806 - accuracy: 0.4553\n",
            "Epoch 00084: accuracy did not improve from 0.46007\n",
            "443/443 [==============================] - 310s 700ms/step - loss: 1.3806 - accuracy: 0.4553 - val_loss: 1.2277 - val_accuracy: 0.5364 - lr: 0.0010\n",
            "Epoch 85/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.4576\n",
            "Epoch 00085: accuracy did not improve from 0.46007\n",
            "443/443 [==============================] - 321s 724ms/step - loss: 1.3782 - accuracy: 0.4576 - val_loss: 1.0895 - val_accuracy: 0.5653 - lr: 0.0010\n",
            "Epoch 86/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3779 - accuracy: 0.4551\n",
            "Epoch 00086: accuracy did not improve from 0.46007\n",
            "443/443 [==============================] - 322s 728ms/step - loss: 1.3779 - accuracy: 0.4551 - val_loss: 1.1375 - val_accuracy: 0.5483 - lr: 0.0010\n",
            "Epoch 87/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3678 - accuracy: 0.4618\n",
            "Epoch 00087: accuracy improved from 0.46007 to 0.46176, saving model to emotions.h5\n",
            "443/443 [==============================] - 312s 704ms/step - loss: 1.3678 - accuracy: 0.4618 - val_loss: 1.1227 - val_accuracy: 0.5784 - lr: 0.0010\n",
            "Epoch 88/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3780 - accuracy: 0.4551\n",
            "Epoch 00088: accuracy did not improve from 0.46176\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.3780 - accuracy: 0.4551 - val_loss: 1.1197 - val_accuracy: 0.5670 - lr: 0.0010\n",
            "Epoch 89/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.4602\n",
            "Epoch 00089: accuracy did not improve from 0.46176\n",
            "443/443 [==============================] - 311s 702ms/step - loss: 1.3782 - accuracy: 0.4602 - val_loss: 1.0988 - val_accuracy: 0.5659 - lr: 0.0010\n",
            "Epoch 90/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3723 - accuracy: 0.4582\n",
            "Epoch 00090: accuracy did not improve from 0.46176\n",
            "443/443 [==============================] - 323s 729ms/step - loss: 1.3723 - accuracy: 0.4582 - val_loss: 1.1899 - val_accuracy: 0.5437 - lr: 0.0010\n",
            "Epoch 91/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3695 - accuracy: 0.4597\n",
            "Epoch 00091: accuracy did not improve from 0.46176\n",
            "443/443 [==============================] - 315s 712ms/step - loss: 1.3695 - accuracy: 0.4597 - val_loss: 1.1285 - val_accuracy: 0.5483 - lr: 0.0010\n",
            "Epoch 92/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3707 - accuracy: 0.4581\n",
            "Epoch 00092: accuracy did not improve from 0.46176\n",
            "443/443 [==============================] - 326s 735ms/step - loss: 1.3707 - accuracy: 0.4581 - val_loss: 1.0920 - val_accuracy: 0.5739 - lr: 0.0010\n",
            "Epoch 93/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3685 - accuracy: 0.4628\n",
            "Epoch 00093: accuracy improved from 0.46176 to 0.46282, saving model to emotions.h5\n",
            "443/443 [==============================] - 315s 711ms/step - loss: 1.3685 - accuracy: 0.4628 - val_loss: 1.1205 - val_accuracy: 0.5835 - lr: 0.0010\n",
            "Epoch 94/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3642 - accuracy: 0.4647\n",
            "Epoch 00094: accuracy improved from 0.46282 to 0.46473, saving model to emotions.h5\n",
            "443/443 [==============================] - 317s 715ms/step - loss: 1.3642 - accuracy: 0.4647 - val_loss: 1.0688 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 95/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3562 - accuracy: 0.4652\n",
            "Epoch 00095: accuracy improved from 0.46473 to 0.46522, saving model to emotions.h5\n",
            "443/443 [==============================] - 327s 738ms/step - loss: 1.3562 - accuracy: 0.4652 - val_loss: 1.0876 - val_accuracy: 0.5784 - lr: 0.0010\n",
            "Epoch 96/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3647 - accuracy: 0.4645\n",
            "Epoch 00096: accuracy did not improve from 0.46522\n",
            "443/443 [==============================] - 329s 742ms/step - loss: 1.3647 - accuracy: 0.4645 - val_loss: 1.1241 - val_accuracy: 0.5602 - lr: 0.0010\n",
            "Epoch 97/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3568 - accuracy: 0.4664\n",
            "Epoch 00097: accuracy improved from 0.46522 to 0.46642, saving model to emotions.h5\n",
            "443/443 [==============================] - 321s 725ms/step - loss: 1.3568 - accuracy: 0.4664 - val_loss: 1.0442 - val_accuracy: 0.5955 - lr: 0.0010\n",
            "Epoch 98/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3713 - accuracy: 0.4614\n",
            "Epoch 00098: accuracy did not improve from 0.46642\n",
            "443/443 [==============================] - 319s 719ms/step - loss: 1.3713 - accuracy: 0.4614 - val_loss: 1.0967 - val_accuracy: 0.5716 - lr: 0.0010\n",
            "Epoch 99/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3634 - accuracy: 0.4625\n",
            "Epoch 00099: accuracy did not improve from 0.46642\n",
            "443/443 [==============================] - 320s 721ms/step - loss: 1.3634 - accuracy: 0.4625 - val_loss: 1.1226 - val_accuracy: 0.5585 - lr: 0.0010\n",
            "Epoch 100/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.4569\n",
            "Epoch 00100: accuracy did not improve from 0.46642\n",
            "443/443 [==============================] - 326s 736ms/step - loss: 1.3702 - accuracy: 0.4569 - val_loss: 1.1123 - val_accuracy: 0.5670 - lr: 0.0010\n",
            "Epoch 101/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3443 - accuracy: 0.4733\n",
            "Epoch 00101: accuracy improved from 0.46642 to 0.47326, saving model to emotions.h5\n",
            "443/443 [==============================] - 316s 714ms/step - loss: 1.3443 - accuracy: 0.4733 - val_loss: 1.0636 - val_accuracy: 0.5841 - lr: 0.0010\n",
            "Epoch 102/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3571 - accuracy: 0.4714\n",
            "Epoch 00102: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 316s 714ms/step - loss: 1.3571 - accuracy: 0.4714 - val_loss: 1.0491 - val_accuracy: 0.5830 - lr: 0.0010\n",
            "Epoch 103/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3557 - accuracy: 0.4637\n",
            "Epoch 00103: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 316s 712ms/step - loss: 1.3557 - accuracy: 0.4637 - val_loss: 1.0963 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 104/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3571 - accuracy: 0.4648\n",
            "Epoch 00104: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 325s 733ms/step - loss: 1.3571 - accuracy: 0.4648 - val_loss: 1.1110 - val_accuracy: 0.5716 - lr: 0.0010\n",
            "Epoch 105/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3553 - accuracy: 0.4665\n",
            "Epoch 00105: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 315s 711ms/step - loss: 1.3553 - accuracy: 0.4665 - val_loss: 1.1001 - val_accuracy: 0.5807 - lr: 0.0010\n",
            "Epoch 106/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3510 - accuracy: 0.4687\n",
            "Epoch 00106: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 324s 731ms/step - loss: 1.3510 - accuracy: 0.4687 - val_loss: 1.0213 - val_accuracy: 0.6057 - lr: 0.0010\n",
            "Epoch 107/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3428 - accuracy: 0.4721\n",
            "Epoch 00107: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 315s 711ms/step - loss: 1.3428 - accuracy: 0.4721 - val_loss: 1.0896 - val_accuracy: 0.5852 - lr: 0.0010\n",
            "Epoch 108/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.4604\n",
            "Epoch 00108: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 316s 714ms/step - loss: 1.3629 - accuracy: 0.4604 - val_loss: 1.0860 - val_accuracy: 0.5784 - lr: 0.0010\n",
            "Epoch 109/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3523 - accuracy: 0.4676\n",
            "Epoch 00109: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 315s 710ms/step - loss: 1.3523 - accuracy: 0.4676 - val_loss: 1.1156 - val_accuracy: 0.5631 - lr: 0.0010\n",
            "Epoch 110/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3450 - accuracy: 0.4696\n",
            "Epoch 00110: accuracy did not improve from 0.47326\n",
            "443/443 [==============================] - 315s 711ms/step - loss: 1.3450 - accuracy: 0.4696 - val_loss: 1.0425 - val_accuracy: 0.5966 - lr: 0.0010\n",
            "Epoch 111/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3455 - accuracy: 0.4757\n",
            "Epoch 00111: accuracy improved from 0.47326 to 0.47567, saving model to emotions.h5\n",
            "443/443 [==============================] - 326s 735ms/step - loss: 1.3455 - accuracy: 0.4757 - val_loss: 1.0472 - val_accuracy: 0.6040 - lr: 0.0010\n",
            "Epoch 112/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3447 - accuracy: 0.4702\n",
            "Epoch 00112: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 328s 739ms/step - loss: 1.3447 - accuracy: 0.4702 - val_loss: 1.1212 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 113/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3436 - accuracy: 0.4720\n",
            "Epoch 00113: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 320s 721ms/step - loss: 1.3436 - accuracy: 0.4720 - val_loss: 1.0848 - val_accuracy: 0.5847 - lr: 0.0010\n",
            "Epoch 114/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3545 - accuracy: 0.4668\n",
            "Epoch 00114: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 318s 718ms/step - loss: 1.3545 - accuracy: 0.4668 - val_loss: 1.0944 - val_accuracy: 0.5778 - lr: 0.0010\n",
            "Epoch 115/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3442 - accuracy: 0.4734\n",
            "Epoch 00115: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 331s 747ms/step - loss: 1.3442 - accuracy: 0.4734 - val_loss: 1.0777 - val_accuracy: 0.5869 - lr: 0.0010\n",
            "Epoch 116/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3438 - accuracy: 0.4733\n",
            "Epoch 00116: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 330s 745ms/step - loss: 1.3438 - accuracy: 0.4733 - val_loss: 1.0656 - val_accuracy: 0.5972 - lr: 0.0010\n",
            "Epoch 117/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3459 - accuracy: 0.4731\n",
            "Epoch 00117: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 321s 724ms/step - loss: 1.3459 - accuracy: 0.4731 - val_loss: 1.1295 - val_accuracy: 0.5659 - lr: 0.0010\n",
            "Epoch 118/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3375 - accuracy: 0.4736\n",
            "Epoch 00118: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 330s 746ms/step - loss: 1.3375 - accuracy: 0.4736 - val_loss: 1.1081 - val_accuracy: 0.5830 - lr: 0.0010\n",
            "Epoch 119/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3459 - accuracy: 0.4729\n",
            "Epoch 00119: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 321s 723ms/step - loss: 1.3459 - accuracy: 0.4729 - val_loss: 1.0776 - val_accuracy: 0.5869 - lr: 0.0010\n",
            "Epoch 120/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3458 - accuracy: 0.4721\n",
            "Epoch 00120: accuracy did not improve from 0.47567\n",
            "443/443 [==============================] - 320s 723ms/step - loss: 1.3458 - accuracy: 0.4721 - val_loss: 1.0635 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 121/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3414 - accuracy: 0.4730\n",
            "Epoch 00121: accuracy did not improve from 0.47567\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "443/443 [==============================] - 330s 744ms/step - loss: 1.3414 - accuracy: 0.4730 - val_loss: 1.0767 - val_accuracy: 0.5892 - lr: 0.0010\n",
            "Epoch 122/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3228 - accuracy: 0.4781\n",
            "Epoch 00122: accuracy improved from 0.47567 to 0.47806, saving model to emotions.h5\n",
            "443/443 [==============================] - 329s 742ms/step - loss: 1.3228 - accuracy: 0.4781 - val_loss: 1.0362 - val_accuracy: 0.5875 - lr: 2.0000e-04\n",
            "Epoch 123/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3262 - accuracy: 0.4810\n",
            "Epoch 00123: accuracy improved from 0.47806 to 0.48102, saving model to emotions.h5\n",
            "443/443 [==============================] - 330s 744ms/step - loss: 1.3262 - accuracy: 0.4810 - val_loss: 1.0086 - val_accuracy: 0.6193 - lr: 2.0000e-04\n",
            "Epoch 124/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3261 - accuracy: 0.4832\n",
            "Epoch 00124: accuracy improved from 0.48102 to 0.48316, saving model to emotions.h5\n",
            "443/443 [==============================] - 329s 743ms/step - loss: 1.3261 - accuracy: 0.4832 - val_loss: 1.0318 - val_accuracy: 0.6102 - lr: 2.0000e-04\n",
            "Epoch 125/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3150 - accuracy: 0.4764\n",
            "Epoch 00125: accuracy did not improve from 0.48316\n",
            "443/443 [==============================] - 327s 739ms/step - loss: 1.3150 - accuracy: 0.4764 - val_loss: 1.0374 - val_accuracy: 0.6080 - lr: 2.0000e-04\n",
            "Epoch 126/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3193 - accuracy: 0.4806\n",
            "Epoch 00126: accuracy did not improve from 0.48316\n",
            "443/443 [==============================] - 329s 742ms/step - loss: 1.3193 - accuracy: 0.4806 - val_loss: 1.0597 - val_accuracy: 0.5926 - lr: 2.0000e-04\n",
            "Epoch 127/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3222 - accuracy: 0.4822\n",
            "Epoch 00127: accuracy did not improve from 0.48316\n",
            "443/443 [==============================] - 322s 726ms/step - loss: 1.3222 - accuracy: 0.4822 - val_loss: 1.0079 - val_accuracy: 0.6085 - lr: 2.0000e-04\n",
            "Epoch 128/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3094 - accuracy: 0.4903\n",
            "Epoch 00128: accuracy improved from 0.48316 to 0.49027, saving model to emotions.h5\n",
            "443/443 [==============================] - 335s 757ms/step - loss: 1.3094 - accuracy: 0.4903 - val_loss: 1.0610 - val_accuracy: 0.5858 - lr: 2.0000e-04\n",
            "Epoch 129/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3112 - accuracy: 0.4855\n",
            "Epoch 00129: accuracy did not improve from 0.49027\n",
            "443/443 [==============================] - 321s 724ms/step - loss: 1.3112 - accuracy: 0.4855 - val_loss: 1.0494 - val_accuracy: 0.5938 - lr: 2.0000e-04\n",
            "Epoch 130/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3151 - accuracy: 0.4896\n",
            "Epoch 00130: accuracy did not improve from 0.49027\n",
            "443/443 [==============================] - 318s 717ms/step - loss: 1.3151 - accuracy: 0.4896 - val_loss: 1.0216 - val_accuracy: 0.6074 - lr: 2.0000e-04\n",
            "Epoch 131/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3124 - accuracy: 0.4875\n",
            "Epoch 00131: accuracy did not improve from 0.49027\n",
            "443/443 [==============================] - 331s 748ms/step - loss: 1.3124 - accuracy: 0.4875 - val_loss: 1.0306 - val_accuracy: 0.6034 - lr: 2.0000e-04\n",
            "Epoch 132/150\n",
            "443/443 [==============================] - ETA: 0s - loss: 1.3080 - accuracy: 0.4913"
          ]
        }
      ]
    }
  ]
}